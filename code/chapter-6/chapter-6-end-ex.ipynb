{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.4\n",
    "\n",
    "Why is it a bad idea to use the period or the square bracket in a column name, given\n",
    "that you also use it to reach hierarchical entities within a data frame?\n",
    "\n",
    "If you have a column named \"person.name\", PySpark interprets it as a nested field within the \"person\" struct. Therefore, using a period in column names can lead to ambiguity and confusion when accessing the columns or performing operations.\n",
    "\n",
    "PySpark uses square brackets to access elements within an array or to specify a range of positions for column selection or filtering. If you have a column named \"my_column[0]\", PySpark interprets it as accessing the first element of the \"my_column\" array. Similarly, if you have a column named \"my_column[0:5]\", PySpark interprets it as selecting a range of elements from the \"my_column\" array. Thus, using square brackets in column names can lead to conflicts or unexpected behavior when using these operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 6.5\n",
    "\n",
    "Although much less common, you can create a data frame from a dictionary. Since\n",
    "dictionaries are so close to JSON documents, build the schema for ingesting the following dictionary. (Both JSON or PySpark schemas are valid here.)\n",
    "\n",
    "```\n",
    "dict_schema = ???\n",
    "spark.createDataFrame([{\"one\": 1, \"two\": [1,2,3]}], schema=dict_schema)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- one: integer (nullable = true)\n",
      " |-- two: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dict_schema = T.StructType([\n",
    "    T.StructField('one', T.IntegerType()),\n",
    "    T.StructField('two', T.ArrayType(T.IntegerType()))\n",
    "])\n",
    "\n",
    "ex_6_5_frame = spark.createDataFrame([{\"one\": 1, \"two\": [1,2,3]}], schema=dict_schema)\n",
    "ex_6_5_frame.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.6\n",
    "\n",
    "Using three_shows, compute the time between the first and last episodes for each\n",
    "show. Which show had the longest tenure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_shows = spark.read.json('../../data/shows/shows-*.json', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _embedded: struct (nullable = true)\n",
      " |    |-- episodes: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- _links: struct (nullable = true)\n",
      " |    |    |    |    |-- self: struct (nullable = true)\n",
      " |    |    |    |    |    |-- href: string (nullable = true)\n",
      " |    |    |    |-- airdate: string (nullable = true)\n",
      " |    |    |    |-- airstamp: string (nullable = true)\n",
      " |    |    |    |-- airtime: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- image: struct (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- original: string (nullable = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- number: long (nullable = true)\n",
      " |    |    |    |-- runtime: long (nullable = true)\n",
      " |    |    |    |-- season: long (nullable = true)\n",
      " |    |    |    |-- summary: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |-- _links: struct (nullable = true)\n",
      " |    |-- previousepisode: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |    |-- self: struct (nullable = true)\n",
      " |    |    |-- href: string (nullable = true)\n",
      " |-- externals: struct (nullable = true)\n",
      " |    |-- imdb: string (nullable = true)\n",
      " |    |-- thetvdb: long (nullable = true)\n",
      " |    |-- tvrage: long (nullable = true)\n",
      " |-- genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- medium: string (nullable = true)\n",
      " |    |-- original: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- network: struct (nullable = true)\n",
      " |    |-- country: struct (nullable = true)\n",
      " |    |    |-- code: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- timezone: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- officialSite: string (nullable = true)\n",
      " |-- premiered: string (nullable = true)\n",
      " |-- rating: struct (nullable = true)\n",
      " |    |-- average: double (nullable = true)\n",
      " |-- runtime: long (nullable = true)\n",
      " |-- schedule: struct (nullable = true)\n",
      " |    |-- days: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- time: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- updated: long (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- webChannel: struct (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |-- weight: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "three_shows.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+\n",
      "|            name|             tenure|\n",
      "+----------------+-------------------+\n",
      "|The Golden Girls|INTERVAL '2429' DAY|\n",
      "|    Breaking Bad|INTERVAL '2079' DAY|\n",
      "|  Silicon Valley|INTERVAL '2072' DAY|\n",
      "+----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    three_shows.select(\n",
    "        'name',\n",
    "        (F.array_max('_embedded.episodes.airdate').cast('date') - F.array_min('_embedded.episodes.airdate').cast('date')).alias('tenure')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Golden Girls had the longest tenure of 2429 days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.7\n",
    "\n",
    "Take the shows data frame and extract the air date and name of each episode in two\n",
    "array columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "shows = spark.read.json('../../data/shows/shows-silicon-valley.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                name|             airdate|\n",
      "+--------------------+--------------------+\n",
      "|[Minimum Viable P...|[2014-04-06, 2014...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shows.select(\n",
    "    '_embedded.episodes.name',\n",
    "    '_embedded.episodes.airdate'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6.8\n",
    "\n",
    "Given the following data frame, create a new data frame that contains a single map\n",
    "from one to square:\n",
    "\n",
    "```\n",
    "exo6_8 = spark.createDataFrame([[1, 2], [2, 4], [3, 9]], [\"one\", \"square\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo6_8 = spark.createDataFrame([[1, 2], [2, 4], [3, 9]], ['one', 'square'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- one: long (nullable = true)\n",
      " |-- square: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exo6_8.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    exo6_8\n",
    "    .groupby()\n",
    "    .agg(\n",
    "        F.collect_list('one').alias('one'),\n",
    "        F.collect_list('square').alias('square')\n",
    "    )\n",
    "    .select(F.map_from_arrays('one', 'square'))\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
