{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we continue to work with the NOAA weather data we worked with in Chapter 9: 10 years' (2010 to 2020) worth of NOAA weather data located in Google BigQuery, which totals over 40 million records. The `bigquery-public-data` is a project available to all.\n",
    "\n",
    "Here, we read in a large amount of data from a warehouse and assemble a single data frame representing weather information across the globe for a period of 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Spark connector package version closest to our installed version of Spark (3.4.1)\n",
    "# spark = SparkSession.builder.config(\n",
    "#     \"spark.jars.packages\",\n",
    "#     \"com.google.cloud.spark:spark-3.3-bigquery:0.32.0\"\n",
    "# ).config(\n",
    "#     \"parentProject\", \"cool-wharf-393713\"\n",
    "# ).getOrCreate()\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract the table reading routine into a reusable function, returning the resulting data frame\n",
    "def read_df_from_bq(year):\n",
    "    return (\n",
    "        spark.read.format(\"bigquery\").option(\n",
    "            \"table\", f\"bigquery-public-data.noaa_gsod.gsod{year}\"\n",
    "        )\n",
    "        .option(\"credentialsFile\", \"../../../../cool-wharf-393713-73800a184f10.json\")\n",
    "        .load()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsod = (\n",
    "#     reduce(\n",
    "#         # use a lambda function over a list comprehension of data frames to union them all\n",
    "#         lambda x, y: x.unionByName(y, allowMissingColumns=True),\n",
    "#         [read_df_from_bq(year) for year in range(2010, 2021)],\n",
    "#     )\n",
    "#     .dropna(subset=[\"year\", \"mo\", \"da\", \"temp\"])\n",
    "#     .where(F.col(\"temp\") != 9999.9)\n",
    "#     .drop(\"date\")\n",
    "# )\n",
    "\n",
    "# Instead, we work locally with three year's worth of data in Parquet format:\n",
    "gsod = spark.read.parquet(\"../../data/window/gsod.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying the coldest day of each year, the long way\n",
    "\n",
    "we want a data frame containing three records, one for each year and showing the station, the date (year, month, day), and the temperature of the coldest day recorded for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|year|  temp|\n",
      "+----+------+\n",
      "|2017|-114.7|\n",
      "|2019|-114.7|\n",
      "|2018|-113.5|\n",
      "+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the lowest temperature for each year using groupBy()\n",
    "coldest_temp = gsod.groupby(\"year\").agg(F.min(\"temp\").alias(\"temp\"))\n",
    "coldest_temp.orderBy(\"temp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+------+\n",
      "|   stn|year| mo| da|  temp|\n",
      "+------+----+---+---+------+\n",
      "|896250|2017| 06| 20|-114.7|\n",
      "|896060|2018| 08| 27|-113.5|\n",
      "|895770|2019| 06| 15|-114.7|\n",
      "+------+----+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a left-semi equi-join on the original table to get \n",
    "# the month and day columns\n",
    "coldest_when = gsod.join(\n",
    "    coldest_temp, how=\"left_semi\", on=[\"year\", \"temp\"]\n",
    ").select(\"stn\", \"year\", \"mo\", \"da\", \"temp\")\n",
    "\n",
    "coldest_when.orderBy(\"year\", \"mo\", \"da\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this instead using a window function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.window.WindowSpec object at 0x000001AE0FBAA040>\n"
     ]
    }
   ],
   "source": [
    "# Create a WindowSpec object by using the Window builder class\n",
    "# This forms a blueprint for an eventual window function.\n",
    "each_year = Window.partitionBy(\"year\")\n",
    "\n",
    "print(each_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+------+------+\n",
      "|year| mo| da|   stn|  temp|\n",
      "+----+---+---+------+------+\n",
      "|2017| 06| 20|896250|-114.7|\n",
      "|2018| 08| 27|896060|-113.5|\n",
      "|2019| 06| 15|895770|-114.7|\n",
      "+----+---+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the minimum temperature for each year using a window function\n",
    "(\n",
    "    gsod\n",
    "    .withColumn(\"min_temp\", F.min(\"temp\").over(each_year))\n",
    "    .where(\"temp = min_temp\")\n",
    "    .select(\"year\", \"mo\", \"da\", \"stn\", \"temp\")\n",
    "    .orderBy(\"year\", \"mo\", \"da\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+\n",
      "|   stn|year| mo| da|temp|count_temp|\n",
      "+------+----+---+---+----+----------+\n",
      "|994979|2017| 12| 11|21.3|        21|\n",
      "|998012|2017| 03| 02|31.4|        24|\n",
      "|719200|2017| 10| 09|60.5|        11|\n",
      "|917350|2018| 04| 21|82.6|         9|\n",
      "|076470|2018| 06| 07|65.0|        24|\n",
      "|996470|2018| 03| 12|55.6|        12|\n",
      "|041680|2019| 02| 19|16.1|        15|\n",
      "|949110|2019| 11| 23|54.9|        14|\n",
      "|998252|2019| 04| 18|44.7|        11|\n",
      "|998166|2019| 03| 20|34.8|        12|\n",
      "+------+----+---+---+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read gsod_light, a smaller data frame with 10 records\n",
    "# (so that we can see it in its entirety when show()ing it)\n",
    "gsod_light = spark.read.parquet(\"../../data/window/gsod_light.parquet\")\n",
    "gsod_light.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a window which partitions the data frame by month,\n",
    "# order each partition by the count_temp column\n",
    "temp_per_month_asc = Window.partitionBy(\"mo\").orderBy(\"count_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+--------+\n",
      "|   stn|year| mo| da|temp|count_temp|rank_tpm|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "|041680|2019| 02| 19|16.1|        15|       1|\n",
      "|996470|2018| 03| 12|55.6|        12|       1|\n",
      "|998166|2019| 03| 20|34.8|        12|       1|\n",
      "|998012|2017| 03| 02|31.4|        24|       3|\n",
      "|917350|2018| 04| 21|82.6|         9|       1|\n",
      "|998252|2019| 04| 18|44.7|        11|       2|\n",
      "|076470|2018| 06| 07|65.0|        24|       1|\n",
      "|719200|2017| 10| 09|60.5|        11|       1|\n",
      "|949110|2019| 11| 23|54.9|        14|       1|\n",
      "|994979|2017| 12| 11|21.3|        21|       1|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rank each day within its month account to count_temp column\n",
    "gsod_light.withColumn(\n",
    "    \"rank_tpm\", F.rank().over(temp_per_month_asc)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+--------+\n",
      "|   stn|year| mo| da|temp|count_temp|rank_tpm|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "|041680|2019| 02| 19|16.1|        15|       1|\n",
      "|996470|2018| 03| 12|55.6|        12|       1|\n",
      "|998166|2019| 03| 20|34.8|        12|       1|\n",
      "|998012|2017| 03| 02|31.4|        24|       2|\n",
      "|917350|2018| 04| 21|82.6|         9|       1|\n",
      "|998252|2019| 04| 18|44.7|        11|       2|\n",
      "|076470|2018| 06| 07|65.0|        24|       1|\n",
      "|719200|2017| 10| 09|60.5|        11|       1|\n",
      "|949110|2019| 11| 23|54.9|        14|       1|\n",
      "|994979|2017| 12| 11|21.3|        21|       1|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can avoid gaps in the ranking using dense_rank()\n",
    "gsod_light.withColumn(\n",
    "    \"rank_tpm\", F.dense_rank().over(temp_per_month_asc)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+------------------+\n",
      "|   stn|year| mo| da|temp|count_temp|          rank_tpm|\n",
      "+------+----+---+---+----+----------+------------------+\n",
      "|994979|2017| 12| 11|21.3|        21|               0.0|\n",
      "|998012|2017| 03| 02|31.4|        24|               0.5|\n",
      "|719200|2017| 10| 09|60.5|        11|               1.0|\n",
      "|996470|2018| 03| 12|55.6|        12|               0.0|\n",
      "|076470|2018| 06| 07|65.0|        24|               0.5|\n",
      "|917350|2018| 04| 21|82.6|         9|               1.0|\n",
      "|041680|2019| 02| 19|16.1|        15|               0.0|\n",
      "|998166|2019| 03| 20|34.8|        12|0.3333333333333333|\n",
      "|998252|2019| 04| 18|44.7|        11|0.6666666666666666|\n",
      "|949110|2019| 11| 23|54.9|        14|               1.0|\n",
      "+------+----+---+---+----+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute percentage rank for every recorded temperature per year\n",
    "temp_each_year = each_year.orderBy(\"temp\")\n",
    "\n",
    "gsod_light.withColumn(\n",
    "    \"rank_tpm\", F.percent_rank().over(temp_each_year)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+--------+\n",
      "|   stn|year| mo| da|temp|count_temp|rank_tpm|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "|994979|2017| 12| 11|21.3|        21|       1|\n",
      "|998012|2017| 03| 02|31.4|        24|       1|\n",
      "|719200|2017| 10| 09|60.5|        11|       2|\n",
      "|996470|2018| 03| 12|55.6|        12|       1|\n",
      "|076470|2018| 06| 07|65.0|        24|       1|\n",
      "|917350|2018| 04| 21|82.6|         9|       2|\n",
      "|041680|2019| 02| 19|16.1|        15|       1|\n",
      "|998166|2019| 03| 20|34.8|        12|       1|\n",
      "|998252|2019| 04| 18|44.7|        11|       2|\n",
      "|949110|2019| 11| 23|54.9|        14|       2|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the two-tile value over the window.\n",
    "# If a value overlaps with two tiles, it takes the value of the lowest one.\n",
    "gsod_light.withColumn(\"rank_tpm\", F.ntile(2).over(temp_each_year)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+--------+\n",
      "|   stn|year| mo| da|temp|count_temp|rank_tpm|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "|994979|2017| 12| 11|21.3|        21|       1|\n",
      "|998012|2017| 03| 02|31.4|        24|       2|\n",
      "|719200|2017| 10| 09|60.5|        11|       3|\n",
      "|996470|2018| 03| 12|55.6|        12|       1|\n",
      "|076470|2018| 06| 07|65.0|        24|       2|\n",
      "|917350|2018| 04| 21|82.6|         9|       3|\n",
      "|041680|2019| 02| 19|16.1|        15|       1|\n",
      "|998166|2019| 03| 20|34.8|        12|       2|\n",
      "|998252|2019| 04| 18|44.7|        11|       3|\n",
      "|949110|2019| 11| 23|54.9|        14|       4|\n",
      "+------+----+---+---+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number records within each window partition using row_number()\n",
    "gsod_light.withColumn(\n",
    "    \"rank_tpm\", F.row_number().over(temp_each_year)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+----------+\n",
      "|   stn|year| mo| da|temp|count_temp|row_number|\n",
      "+------+----+---+---+----+----------+----------+\n",
      "|041680|2019| 02| 19|16.1|        15|         1|\n",
      "|998012|2017| 03| 02|31.4|        24|         1|\n",
      "|996470|2018| 03| 12|55.6|        12|         2|\n",
      "|998166|2019| 03| 20|34.8|        12|         3|\n",
      "|998252|2019| 04| 18|44.7|        11|         1|\n",
      "|917350|2018| 04| 21|82.6|         9|         2|\n",
      "|076470|2018| 06| 07|65.0|        24|         1|\n",
      "|719200|2017| 10| 09|60.5|        11|         1|\n",
      "|949110|2019| 11| 23|54.9|        14|         1|\n",
      "|994979|2017| 12| 11|21.3|        21|         1|\n",
      "+------+----+---+---+----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a window with a descending-ordered column\n",
    "temp_per_month_desc = Window.partitionBy(\"mo\").orderBy(\n",
    "    F.col(\"count_temp\").desc()\n",
    ")\n",
    "\n",
    "gsod_light.withColumn(\n",
    "    \"row_number\", F.row_number().over(temp_per_month_desc)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic functions: looking back and ahead\n",
    "\n",
    "We can access records bofore or after using LAG() and LEAD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+-------------+---------------+\n",
      "|   stn|year| mo| da|temp|count_temp|previous_temp|previous_temp_2|\n",
      "+------+----+---+---+----+----------+-------------+---------------+\n",
      "|994979|2017| 12| 11|21.3|        21|         null|           null|\n",
      "|998012|2017| 03| 02|31.4|        24|         21.3|           null|\n",
      "|719200|2017| 10| 09|60.5|        11|         31.4|           21.3|\n",
      "|996470|2018| 03| 12|55.6|        12|         null|           null|\n",
      "|076470|2018| 06| 07|65.0|        24|         55.6|           null|\n",
      "|917350|2018| 04| 21|82.6|         9|         65.0|           55.6|\n",
      "|041680|2019| 02| 19|16.1|        15|         null|           null|\n",
      "|998166|2019| 03| 20|34.8|        12|         16.1|           null|\n",
      "|998252|2019| 04| 18|44.7|        11|         34.8|           16.1|\n",
      "|949110|2019| 11| 23|54.9|        14|         44.7|           34.8|\n",
      "+------+----+---+---+----+----------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsod_light.withColumn(\n",
    "    \"previous_temp\", F.lag(\"temp\").over(temp_each_year)\n",
    ").withColumn(\n",
    "    \"previous_temp_2\", F.lag(\"temp\", 2).over(temp_each_year)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+------------------+------------------+\n",
      "|   stn|year| mo| da|temp|count_temp|      percent_rank|         cume_dist|\n",
      "+------+----+---+---+----+----------+------------------+------------------+\n",
      "|994979|2017| 12| 11|21.3|        21|               0.0|0.3333333333333333|\n",
      "|998012|2017| 03| 02|31.4|        24|               0.5|0.6666666666666666|\n",
      "|719200|2017| 10| 09|60.5|        11|               1.0|               1.0|\n",
      "|996470|2018| 03| 12|55.6|        12|               0.0|0.3333333333333333|\n",
      "|076470|2018| 06| 07|65.0|        24|               0.5|0.6666666666666666|\n",
      "|917350|2018| 04| 21|82.6|         9|               1.0|               1.0|\n",
      "|041680|2019| 02| 19|16.1|        15|               0.0|              0.25|\n",
      "|998166|2019| 03| 20|34.8|        12|0.3333333333333333|               0.5|\n",
      "|998252|2019| 04| 18|44.7|        11|0.6666666666666666|              0.75|\n",
      "|949110|2019| 11| 23|54.9|        14|               1.0|               1.0|\n",
      "+------+----+---+---+----+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare percent_rank() and cum_dist over a window\n",
    "gsod_light.withColumn(\n",
    "    \"percent_rank\", F.percent_rank().over(temp_each_year)\n",
    ").withColumn(\"cume_dist\", F.cume_dist().over(temp_each_year)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.2\n",
    "\n",
    "If you have a window where all the ordered values are the same, what is the result of applying ntile() to the window?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|index|value|\n",
      "+-----+-----+\n",
      "|    0|    2|\n",
      "|    0|    2|\n",
      "|    0|    2|\n",
      "|    0|    2|\n",
      "|    1|    2|\n",
      "|    1|    2|\n",
      "|    1|    2|\n",
      "|    1|    2|\n",
      "|    2|    2|\n",
      "|    2|    2|\n",
      "|    2|    2|\n",
      "|    2|    2|\n",
      "|    3|    2|\n",
      "|    3|    2|\n",
      "|    3|    2|\n",
      "|    3|    2|\n",
      "|    4|    2|\n",
      "|    4|    2|\n",
      "|    4|    2|\n",
      "|    4|    2|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntile_example = spark.createDataFrame(\n",
    "    [[x // 4, 2] for x in range(1001)], [\"index\", \"value\"] \n",
    ")\n",
    "\n",
    "ntile_example.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.window.WindowSpec object at 0x000001AE152C15E0>\n"
     ]
    }
   ],
   "source": [
    "ntile_window = Window.partitionBy(\"index\").orderBy(\"value\")\n",
    "\n",
    "print(ntile_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+\n",
      "|index|value|3tile|\n",
      "+-----+-----+-----+\n",
      "|    0|    2|    1|\n",
      "|    0|    2|    1|\n",
      "|    0|    2|    2|\n",
      "|    0|    2|    3|\n",
      "|    1|    2|    1|\n",
      "|    1|    2|    1|\n",
      "|    1|    2|    2|\n",
      "|    1|    2|    3|\n",
      "|    2|    2|    1|\n",
      "|    2|    2|    1|\n",
      "+-----+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntile_example.withColumn(\"3tile\", F.ntile(3).over(ntile_window)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using row and range boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+------------------+------------------+\n",
      "|   stn|year| mo| da|temp|count_temp|            avg_NO|             avg_O|\n",
      "+------+----+---+---+----+----------+------------------+------------------+\n",
      "|994979|2017| 12| 11|21.3|        21|37.733333333333334|              21.3|\n",
      "|998012|2017| 03| 02|31.4|        24|37.733333333333334|             26.35|\n",
      "|719200|2017| 10| 09|60.5|        11|37.733333333333334|37.733333333333334|\n",
      "|996470|2018| 03| 12|55.6|        12| 67.73333333333333|              55.6|\n",
      "|076470|2018| 06| 07|65.0|        24| 67.73333333333333|              60.3|\n",
      "|917350|2018| 04| 21|82.6|         9| 67.73333333333333| 67.73333333333333|\n",
      "|041680|2019| 02| 19|16.1|        15|            37.625|              16.1|\n",
      "|998166|2019| 03| 20|34.8|        12|            37.625|             25.45|\n",
      "|998252|2019| 04| 18|44.7|        11|            37.625|31.866666666666664|\n",
      "|949110|2019| 11| 23|54.9|        14|            37.625|            37.625|\n",
      "+------+----+---+---+----+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We get different results when we average over an ordered window\n",
    "# than we do when we average over an unordered window\n",
    "not_ordered = Window.partitionBy(\"year\")\n",
    "ordered = not_ordered.orderBy(\"temp\")\n",
    "\n",
    "gsod_light.withColumn(\n",
    "    \"avg_NO\", F.avg(\"temp\").over(not_ordered)\n",
    ").withColumn(\n",
    "    \"avg_O\", F.avg(\"temp\").over(ordered)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a window spec with explicit window boundaries\n",
    "not_ordered = Window.partitionBy(\"year\").rowsBetween(\n",
    "    Window.unboundedPreceding, Window.unboundedFollowing\n",
    ")\n",
    "ordered = not_ordered.partitionBy(\"temp\").rowsBetween(\n",
    "    Window.unboundedPreceding, Window.currentRow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+----------+----------+\n",
      "|   stn|year| mo| da|temp|count_temp|        dt|    dt_num|\n",
      "+------+----+---+---+----+----------+----------+----------+\n",
      "|994979|2019| 12| 11|21.3|        21|2019-12-11|1576022400|\n",
      "|998012|2019| 03| 02|31.4|        24|2019-03-02|1551484800|\n",
      "|719200|2019| 10| 09|60.5|        11|2019-10-09|1570575600|\n",
      "|917350|2019| 04| 21|82.6|         9|2019-04-21|1555801200|\n",
      "|076470|2019| 06| 07|65.0|        24|2019-06-07|1559862000|\n",
      "|996470|2019| 03| 12|55.6|        12|2019-03-12|1552348800|\n",
      "|041680|2019| 02| 19|16.1|        15|2019-02-19|1550534400|\n",
      "|949110|2019| 11| 23|54.9|        14|2019-11-23|1574467200|\n",
      "|998252|2019| 04| 18|44.7|        11|2019-04-18|1555542000|\n",
      "|998166|2019| 03| 20|34.8|        12|2019-03-20|1553040000|\n",
      "+------+----+---+---+----+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a date column to apply range a range window on\n",
    "gsod_light_p = (\n",
    "    gsod_light\n",
    "    .withColumn(\"year\", F.lit(2019))\n",
    "    .withColumn(\"dt\",\n",
    "             F.to_date(\n",
    "                 F.concat_ws(\"-\", F.col(\"year\"), F.col(\"mo\"), F.col(\"da\"))\n",
    "             )\n",
    "        )\n",
    "    .withColumn(\"dt_num\", F.unix_timestamp(\"dt\"))\n",
    ")\n",
    "\n",
    "gsod_light_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+----------+----------+------------------+\n",
      "|   stn|year| mo| da|temp|count_temp|        dt|    dt_num|         avg_count|\n",
      "+------+----+---+---+----+----------+----------+----------+------------------+\n",
      "|041680|2019| 02| 19|16.1|        15|2019-02-19|1550534400|             15.75|\n",
      "|998012|2019| 03| 02|31.4|        24|2019-03-02|1551484800|             15.75|\n",
      "|996470|2019| 03| 12|55.6|        12|2019-03-12|1552348800|             15.75|\n",
      "|998166|2019| 03| 20|34.8|        12|2019-03-20|1553040000|              14.8|\n",
      "|998252|2019| 04| 18|44.7|        11|2019-04-18|1555542000|10.666666666666666|\n",
      "|917350|2019| 04| 21|82.6|         9|2019-04-21|1555801200|              10.0|\n",
      "|076470|2019| 06| 07|65.0|        24|2019-06-07|1559862000|              24.0|\n",
      "|719200|2019| 10| 09|60.5|        11|2019-10-09|1570575600|              11.0|\n",
      "|949110|2019| 11| 23|54.9|        14|2019-11-23|1574467200|              17.5|\n",
      "|994979|2019| 12| 11|21.3|        21|2019-12-11|1576022400|              17.5|\n",
      "+------+----+---+---+----+----------+----------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the average temperature for a 60 day sliding window\n",
    "# Note that rangeBetween() uses the VALUES rather than ROW NUMBERs.\n",
    "ONE_MONTH_ISH = 30 * 60 * 60 * 24\n",
    "one_month_ish_before_after = (\n",
    "    Window.partitionBy(\"year\")\n",
    "    .orderBy(\"dt_num\")\n",
    "    .rangeBetween(-ONE_MONTH_ISH, ONE_MONTH_ISH)\n",
    ")\n",
    "\n",
    "gsod_light_p.withColumn(\n",
    "    \"avg_count\", F.avg(\"count_temp\").over(one_month_ish_before_after)\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.3\n",
    "\n",
    "If you have a data frame with 1,000,001 rows, where the ordered column ord is defined by `F.lit(10)`, what is the result of the following window functions?\n",
    "\n",
    "1) `F.count(\"ord\").over(Window.partitionBy().orderBy(\"ord\").rowsBetween(-2, 2))`\n",
    "\n",
    "2) `F.count(\"ord\").over(Window.partitionBy().orderBy(\"ord\").rangeBetween(-2, 2))`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|ord|\n",
      "+---+\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "| 10|\n",
      "+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_example = spark.createDataFrame(\n",
    "    [[10] for x in range(1000001)], [\"ord\"] \n",
    ")\n",
    "\n",
    "count_example.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+\n",
      "|ord|row|  range|\n",
      "+---+---+-------+\n",
      "| 10|  3|1000001|\n",
      "| 10|  4|1000001|\n",
      "| 10|  5|1000001|\n",
      "| 10|  5|1000001|\n",
      "| 10|  5|1000001|\n",
      "| 10|  5|1000001|\n",
      "| 10|  5|1000001|\n",
      "| 10|  5|1000001|\n",
      "| 10|  5|1000001|\n",
      "| 10|  5|1000001|\n",
      "+---+---+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_example.select(\n",
    "    \"ord\",\n",
    "    F.count(\"ord\")\n",
    "    .over(Window.partitionBy().orderBy(\"ord\").rowsBetween(-2, 2))\n",
    "    .alias(\"row\"),\n",
    "    F.count(\"ord\")\n",
    "    .over(Window.partitionBy().orderBy(\"ord\").rangeBetween(-2, 2))\n",
    "    .alias(\"range\"),\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pandas UDF over window intervals\n",
    "@F.pandas_udf(\"double\")\n",
    "def median(vals: pd.Series) -> float:\n",
    "    return vals.median()\n",
    "\n",
    "gsod_light.withColumn(\n",
    "    \"median_temp\", median(\"temp\").over(Window.partitionBy(\"year\")) \n",
    ").withColumn(\n",
    "    \"median_temp_g\",\n",
    "    median(\"temp\").over(\n",
    "        Window.partitionBy(\"year\").orderBy(\"mo\", \"da\") \n",
    "    ) \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+-----------+-------------+\n",
      "|   stn|year| mo| da|temp|count_temp|median_temp|median_temp_g|\n",
      "+------+----+---+---+----+----------+-----------+-------------+\n",
      "|998012|2017| 03| 02|31.4|        24|       31.4|         31.4|\n",
      "|719200|2017| 10| 09|60.5|        11|       31.4|         31.4|\n",
      "|994979|2017| 12| 11|21.3|        21|       31.4|         31.4|\n",
      "|996470|2018| 03| 12|55.6|        12|       65.0|         55.6|\n",
      "|917350|2018| 04| 21|82.6|         9|       65.0|         55.6|\n",
      "|076470|2018| 06| 07|65.0|        24|       65.0|         65.0|\n",
      "|041680|2019| 02| 19|16.1|        15|       34.8|         16.1|\n",
      "|998166|2019| 03| 20|34.8|        12|       34.8|         16.1|\n",
      "|998252|2019| 04| 18|44.7|        11|       34.8|         34.8|\n",
      "|949110|2019| 11| 23|54.9|        14|       34.8|         34.8|\n",
      "+------+----+---+---+----+----------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate median_temp for each year\n",
    "gsod_light = gsod_light.withColumn(\n",
    "    \"median_temp\", F.expr(\"percentile_approx(temp, 0.5)\").over(Window.partitionBy(\"year\"))\n",
    ")\n",
    "\n",
    "# Calculate median_temp_g for each year, ordering by \"mo\" and \"da\"\n",
    "gsod_light = gsod_light.withColumn(\n",
    "    \"median_temp_g\",\n",
    "    F.expr(\"percentile_approx(temp, 0.5)\").over(Window.partitionBy(\"year\").orderBy(\"mo\", \"da\"))\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "gsod_light.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.4\n",
    "\n",
    "Using the following code, first identify the day with the warmest temperature for each year, and then compute the average temperature. What happens when there are more than two occurrences?\n",
    "\n",
    "```\n",
    "each_year = Window.partitionBy(\"year\")\n",
    "(gsod\n",
    " .withColumn(\"min_temp\", F.min(\"temp\").over(each_year))\n",
    " .where(\"temp = min_temp\")\n",
    " .select(\"year\", \"mo\", \"da\", \"stn\", \"temp\")\n",
    " .orderBy(\"year\", \"mo\", \"da\")\n",
    " .show())\n",
    "```\n",
    "\n",
    "Answer: Where there are more than two occurrences, all occurrences are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+------+-----+--------+\n",
      "|year| mo| da|   stn| temp|avg_temp|\n",
      "+----+---+---+------+-----+--------+\n",
      "|2017| 07| 06|403770|110.0|   110.0|\n",
      "|2017| 07| 24|999999|110.0|   110.0|\n",
      "|2018| 06| 06|405860|110.0|   110.0|\n",
      "|2018| 07| 12|407036|110.0|   110.0|\n",
      "|2018| 07| 16|999999|110.0|   110.0|\n",
      "|2018| 07| 26|723805|110.0|   110.0|\n",
      "|2019| 07| 07|405870|110.0|   110.0|\n",
      "|2019| 07| 14|999999|110.0|   110.0|\n",
      "|2019| 07| 15|606030|110.0|   110.0|\n",
      "|2019| 08| 02|606450|110.0|   110.0|\n",
      "+----+---+---+------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "each_year = Window.partitionBy(\"year\")\n",
    "(\n",
    "    gsod\n",
    "    .withColumn(\"max_temp\", F.max(\"temp\").over(each_year))\n",
    "    .where(\"temp = max_temp\")\n",
    "    .select(\"year\", \"mo\", \"da\", \"stn\", \"temp\")\n",
    "    .withColumn(\"avg_temp\", F.mean(\"temp\").over(each_year))\n",
    "    .orderBy(\"year\", \"mo\", \"da\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.5\n",
    "\n",
    "How would you create a rank that is full, meaning that each record within a the `temp_per_month_asc` has a unique rank, using the `gsod_light` data frame? For records with an identical `orderBy()` value, the order of rank does not matter. \n",
    "```temp_per_month_asc = Window.partitionBy(\"mo\").orderBy(\"count_temp\") \n",
    "gsod_light = spark.read.parquet(\"../../data/window/gsod_light.parquet\")\n",
    "gsod_light.withColumn(\n",
    " \"rank_tpm\", F.rank().over(temp_per_month_asc) \n",
    ").show()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+------+----+----------+--------+\n",
      "|year| mo| da|   stn|temp|count_temp|rank_tpm|\n",
      "+----+---+---+------+----+----------+--------+\n",
      "|2019| 02| 19|041680|16.1|        15|       1|\n",
      "|2018| 03| 12|996470|55.6|        12|       1|\n",
      "|2019| 03| 20|998166|34.8|        12|       2|\n",
      "|2017| 03| 02|998012|31.4|        24|       3|\n",
      "|2018| 04| 21|917350|82.6|         9|       1|\n",
      "|2019| 04| 18|998252|44.7|        11|       2|\n",
      "|2018| 06| 07|076470|65.0|        24|       1|\n",
      "|2017| 10| 09|719200|60.5|        11|       1|\n",
      "|2019| 11| 23|949110|54.9|        14|       1|\n",
      "|2017| 12| 11|994979|21.3|        21|       1|\n",
      "+----+---+---+------+----+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsod_light = spark.read.parquet(\"../../data/window/gsod_light.parquet\")\n",
    "\n",
    "temp_per_month_rank = Window.partitionBy(\"mo\").orderBy(\n",
    " \"count_temp\", \"row_tpm\"\n",
    ")\n",
    "\n",
    "(\n",
    "    gsod_light\n",
    "    .withColumn(\n",
    "        \"row_tpm\", F.row_number().over(temp_per_month_asc)\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"rank_tpm\", F.rank().over(temp_per_month_rank)\n",
    "    )\n",
    "    .select(\"year\", \"mo\", \"da\", \"stn\", \"temp\", \"count_temp\", \"rank_tpm\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.6\n",
    "\n",
    "Take the gsod data frame (not the gsod_light) and create a new column that is True\n",
    "if the temperature at a given station is maximum for that station and a time window of\n",
    "seven days (before and after), and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+----+---+---+-----+----------+------+----------+------+---------+------+---------+-----+-----------+----+----------+-----+-----+-----+--------+-----+--------+----+---------+-----+---+------------+----------------+----+-------+--------------------+----------+----------+\n",
      "|   stn| wban|year| mo| da| temp|count_temp|  dewp|count_dewp|   slp|count_slp|   stp|count_stp|visib|count_visib|wdsp|count_wdsp|mxpsd| gust|  max|flag_max|  min|flag_min|prcp|flag_prcp| sndp|fog|rain_drizzle|snow_ice_pellets|hail|thunder|tornado_funnel_cloud|        dt|    dt_num|\n",
      "+------+-----+----+---+---+-----+----------+------+----------+------+---------+------+---------+-----+-----------+----+----------+-----+-----+-----+--------+-----+--------+----+---------+-----+---+------------+----------------+----+-------+--------------------+----------+----------+\n",
      "|994979|99999|2017| 12| 11| 21.3|        21|9999.9|         0|1014.9|       13|9999.9|        0|999.9|          0|12.0|        13| 21.0|999.9| 27.3|       *| 17.1|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-12-11|1512950400|\n",
      "|998012|99999|2017| 03| 02| 31.4|        24|9999.9|         0|1019.4|       14|9999.9|        0|999.9|          0|15.5|        14| 24.1|999.9| 33.6|       *| 29.7|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-03-02|1488412800|\n",
      "|719200|99999|2017| 10| 09| 60.5|        11|9999.9|         0|1016.6|       11|1016.5|        8|999.9|          0|11.0|        11| 21.0|999.9| 66.6|        | 58.8|        | 0.0|        G|  0.4|  0|           0|               0|   0|      0|                   0|2017-10-09|1507503600|\n",
      "|998258|99999|2017| 05| 01| 44.9|        13|9999.9|         0|1022.3|       13|9999.9|        0|999.9|          0| 4.6|        13|  8.0|999.9| 48.7|       *| 42.1|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-05-01|1493593200|\n",
      "|997737|99999|2017| 03| 10|  6.8|        24|9999.9|         0|1032.9|       15|9999.9|        0|999.9|          0| 8.1|        15| 14.0|999.9| 19.0|       *| -3.8|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-03-10|1489104000|\n",
      "|025010|99999|2017| 11| 24| 44.8|        24|9999.9|         0|1002.5|       13| 999.7|       13|999.9|          0|23.8|        24| 33.0| 35.2| 48.6|        | 41.5|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-11-24|1511481600|\n",
      "|992190|99999|2017| 10| 08| 54.6|        10|9999.9|         0|1026.5|       10|9999.9|        0|999.9|          0|18.8|        10| 23.3|999.9| 55.6|       *| 53.2|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-10-08|1507417200|\n",
      "|719200|99999|2017| 09| 16| 58.5|         9|9999.9|         0|1021.1|        9|1020.5|        8|999.9|          0| 4.4|         9|  7.6|999.9| 63.5|        | 52.5|        | 0.0|        G|999.9|  0|           0|               0|   0|      0|                   0|2017-09-16|1505516400|\n",
      "|997356|99999|2017| 07| 10| 81.9|        15|9999.9|         0|1017.0|       13|9999.9|        0|999.9|          0| 5.2|        15|  9.9|999.9| 86.0|       *| 77.2|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-07-10|1499641200|\n",
      "|997737|99999|2017| 10| 12| 55.4|        24|9999.9|         0|1019.4|       14|9999.9|        0|999.9|          0| 9.0|        14| 12.4|999.9| 57.4|       *| 52.9|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-10-12|1507762800|\n",
      "|994045|99999|2017| 11| 19| 61.4|        11|9999.9|         0|1015.7|       11|9999.9|        0|999.9|          0|12.2|        11| 15.9|999.9| 64.8|       *| 57.9|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-11-19|1511049600|\n",
      "|998485|99999|2017| 10| 28| 64.9|        13|9999.9|         0|1011.9|       13|9999.9|        0|999.9|          0|11.2|        13| 18.1|999.9| 73.9|       *| 53.2|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-10-28|1509145200|\n",
      "|943930|99999|2017| 09| 14| 75.3|        12|9999.9|         0|1015.3|       12|1013.8|       12|999.9|          0| 9.8|        12| 20.0|999.9| 76.6|       *| 72.7|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-09-14|1505343600|\n",
      "|817320|99999|2017| 01| 25| 83.2|        15|9999.9|         0|1010.7|       15|1008.4|       15|999.9|          0| 0.0|        15|999.9|999.9| 92.7|        | 74.7|        | 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-01-25|1485302400|\n",
      "|817320|99999|2017| 06| 02| 78.4|        14|9999.9|         0|1012.1|       14|1009.8|       14|999.9|          0| 0.0|        14|999.9|999.9| 86.5|        | 75.7|        | 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-06-02|1496358000|\n",
      "|996080|99999|2017| 11| 07| 58.4|        11|9999.9|         0|1011.0|       11|1010.8|       11|999.9|          0|16.4|        11| 23.3|999.9| 60.3|       *| 56.8|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-11-07|1510012800|\n",
      "|700632|26645|2017| 01| 18|-38.6|        23|9999.9|         0|1003.1|       12|1002.2|       23|  6.0|         23| 2.1|        23|  5.1|999.9|-32.8|       *|-43.6|       *| 0.0|        D|999.9|  0|           0|               1|   0|      0|                   0|2017-01-18|1484697600|\n",
      "|998437|99999|2017| 10| 21| 83.2|        13|9999.9|         0|1011.6|       13|9999.9|        0|999.9|          0| 5.2|        13| 11.1|999.9| 89.2|       *| 75.4|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-10-21|1508540400|\n",
      "|998166|99999|2017| 07| 02| 71.5|        24|9999.9|         0|1015.4|       15|9999.9|        0|999.9|          0|11.5|        15| 18.1|999.9| 74.5|       *| 67.8|       *| 0.0|        I|999.9|  0|           0|               0|   0|      0|                   0|2017-07-02|1498950000|\n",
      "|714850|99999|2017| 08| 05| 55.0|        14|9999.9|         0|1013.0|       14|1010.9|        8|999.9|          0| 6.0|        14| 11.1|999.9| 61.3|        | 50.5|        | 0.0|        G|999.9|  0|           0|               0|   0|      0|                   0|2017-08-05|1501887600|\n",
      "+------+-----+----+---+---+-----+----------+------+----------+------+---------+------+---------+-----+-----------+----+----------+-----+-----+-----+--------+-----+--------+----+---------+-----+---+------------+----------------+----+-------+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a date column to apply a range window on:\n",
    "gsod_p = (\n",
    "    gsod\n",
    "    .withColumn(\n",
    "        \"dt\",\n",
    "        F.to_date(\n",
    "            F.concat_ws(\"-\", F.col(\"year\"), F.col(\"mo\"), F.col(\"da\"))\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"dt_num\", F.unix_timestamp(\"dt\")\n",
    "    )\n",
    ")\n",
    "\n",
    "gsod_p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----------+----+--------+------+\n",
      "|   stn|year| mo| da|    dt_num|temp|max_temp|is_max|\n",
      "+------+----+---+---+----------+----+--------+------+\n",
      "|010060|2017| 01| 02|1483315200|20.2|    25.7| false|\n",
      "|010060|2017| 01| 03|1483401600|17.9|    25.7| false|\n",
      "|010060|2017| 01| 04|1483488000|19.5|    25.7| false|\n",
      "|010060|2017| 01| 05|1483574400|25.7|    25.7|  true|\n",
      "|010060|2017| 01| 06|1483660800|21.1|    25.7| false|\n",
      "|010060|2017| 01| 07|1483747200|19.1|    25.7| false|\n",
      "|010060|2017| 01| 08|1483833600|13.5|    25.7| false|\n",
      "|010060|2017| 01| 09|1483920000|10.3|    27.8| false|\n",
      "|010060|2017| 01| 10|1484006400| 6.0|    27.8| false|\n",
      "|010060|2017| 01| 11|1484092800| 7.0|    27.8| false|\n",
      "|010060|2017| 01| 12|1484179200|11.1|    27.8| false|\n",
      "|010060|2017| 01| 13|1484265600|15.1|    27.8| false|\n",
      "|010060|2017| 01| 14|1484352000|24.0|    27.8| false|\n",
      "|010060|2017| 01| 15|1484438400|20.1|    27.8| false|\n",
      "|010060|2017| 01| 16|1484524800|27.8|    27.8|  true|\n",
      "|010060|2017| 01| 17|1484611200|22.4|    27.8| false|\n",
      "|010060|2017| 01| 18|1484697600| 6.1|    27.8| false|\n",
      "|010060|2017| 01| 19|1484784000| 6.5|    27.8| false|\n",
      "|010060|2017| 01| 20|1484870400|10.6|    27.8| false|\n",
      "|010060|2017| 01| 21|1484956800|19.3|    27.8| false|\n",
      "+------+----+---+---+----------+----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEVEN_DAYS = 7 * 24 * 60 * 60\n",
    "seven_days_before_and_after = (\n",
    "    Window.partitionBy(\"stn\")\n",
    "    .orderBy(\"dt_num\")\n",
    "    .rangeBetween(-SEVEN_DAYS, SEVEN_DAYS)\n",
    ")\n",
    "\n",
    "(\n",
    "    gsod_p\n",
    "    .withColumn(\"max_temp\", F.max(\"temp\").over(seven_days_before_and_after))\n",
    "    .withColumn(\"is_max\", F.when(F.col(\"temp\") == F.col(\"max_temp\"), True).otherwise(False))\n",
    "    .select(\"stn\", \"year\", \"mo\", \"da\", \"dt_num\", \"temp\", \"max_temp\", \"is_max\")\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10.7\n",
    "\n",
    "How would you create a window like the code that follows, but taking into account\n",
    "that months have different number of days? For instance, March has 31 days, but April\n",
    "has 30 days, so you can’t do a window spec over a set number of days.\n",
    " (Hint: My solution doesn’t use dt_num.)\n",
    "\n",
    "```\n",
    "ONE_MONTH_ISH = 30 * 60 * 60 * 24 # or 2_592_000 seconds\n",
    "one_month_ish_before_and_after = (\n",
    " Window.partitionBy(\"year\")\n",
    " .orderBy(\"dt_num\")\n",
    " .rangeBetween(-ONE_MONTH_ISH, ONE_MONTH_ISH)\n",
    " )\n",
    "gsod_light_p = (\n",
    " gsod_light.withColumn(\"year\", F.lit(2019))\n",
    " .withColumn(\n",
    " \"dt\",\n",
    " F.to_date(\n",
    " F.concat_ws(\"-\", F.col(\"year\"), F.col(\"mo\"), F.col(\"da\"))\n",
    " ),\n",
    " )\n",
    " .withColumn(\"dt_num\", F.unix_timestamp(\"dt\"))\n",
    ")\n",
    "gsod_light_p.withColumn(\n",
    " \"avg_count\", F.avg(\"count_temp\").over(one_month_ish_before_and_after)\n",
    ").show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+---+----+----------+------+------------------+\n",
      "|   stn|year| mo| da|temp|count_temp|num_mo|         avg_count|\n",
      "+------+----+---+---+----+----------+------+------------------+\n",
      "|041680|2019| 02| 19|16.1|        15| 24230|             15.75|\n",
      "|998012|2019| 03| 02|31.4|        24| 24231|13.833333333333334|\n",
      "|996470|2019| 03| 12|55.6|        12| 24231|13.833333333333334|\n",
      "|998166|2019| 03| 20|34.8|        12| 24231|13.833333333333334|\n",
      "|917350|2019| 04| 21|82.6|         9| 24232|              13.6|\n",
      "|998252|2019| 04| 18|44.7|        11| 24232|              13.6|\n",
      "|076470|2019| 06| 07|65.0|        24| 24234|              24.0|\n",
      "|719200|2019| 10| 09|60.5|        11| 24238|              12.5|\n",
      "|949110|2019| 11| 23|54.9|        14| 24239|15.333333333333334|\n",
      "|994979|2019| 12| 11|21.3|        21| 24240|              17.5|\n",
      "+------+----+---+---+----+----------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_month_before_and_after = (\n",
    "    Window.partitionBy(\"year\").orderBy(\"num_mo\").rangeBetween(-1, 1)\n",
    ")\n",
    "\n",
    "(\n",
    "    gsod_light_p\n",
    "    .drop(\"dt\", \"dt_num\")\n",
    "    .withColumn(\"num_mo\", F.col(\"year\").cast(\"int\") * 12 + F.col(\"mo\").cast(\"int\"))\n",
    "    .withColumn(\"avg_count\", F.avg(\"count_temp\").over(one_month_before_and_after))\n",
    "    .show()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydata-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
