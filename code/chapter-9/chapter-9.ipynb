{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from time import sleep\n",
    "from typing import Iterator, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we work with 10 years' (2010 to 2020) worth of NOAA weather data located in Google BigQuery, which totals over 40 million records. The `bigquery-public-data` is a project available to all.\n",
    "\n",
    "Here, we read in a large amount of data from a warehouse and assemble a single data frame representing weather information across the globe for a period of 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Spark connector package version closest to our installed version of Spark (3.4.1)\n",
    "spark = SparkSession.builder.config(\n",
    "    \"spark.jars.packages\",\n",
    "    \"com.google.cloud.spark:spark-3.3-bigquery:0.32.0\"\n",
    ").config(\n",
    "    \"parentProject\", \"cool-wharf-393713\"\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract the table reading routine into a reusable function, returning the resulting data frame\n",
    "def read_df_from_bq(year):\n",
    "    return (\n",
    "        spark.read.format(\"bigquery\").option(\n",
    "            \"table\", f\"bigquery-public-data.noaa_gsod.gsod{year}\"\n",
    "        )\n",
    "        .option(\"credentialsFile\", \"../../../../cool-wharf-393713-73800a184f10.json\")\n",
    "        .load()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsod = (\n",
    "    reduce(\n",
    "        # use a lambda function over a list comprehension of data frames to union them all\n",
    "        lambda x, y: x.unionByName(y, allowMissingColumns=True),\n",
    "        [read_df_from_bq(year) for year in range(2010, 2021)],\n",
    "    )\n",
    "    .dropna(subset=[\"year\", \"mo\", \"da\", \"temp\"])\n",
    "    .where(F.col(\"temp\") != 9999.9)\n",
    "    .drop(\"date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas scalar UDF that transforms Fahrenheit into Celsius\n",
    "@F.pandas_udf(T.DoubleType())\n",
    "def f_to_c(degrees: pd.Series) -> pd.Series:\n",
    "    \"\"\"Transforms Fahrenheight to Celcius.\"\"\"\n",
    "    return (degrees - 32) *5 / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|temp|\n",
      "+----+\n",
      "|69.8|\n",
      "|74.5|\n",
      "|64.2|\n",
      "|76.4|\n",
      "|15.5|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsod.select(\"temp\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|temp|             temp_c|\n",
      "+----+-------------------+\n",
      "|37.2| 2.8888888888888906|\n",
      "|71.6| 21.999999999999996|\n",
      "|70.4| 21.333333333333336|\n",
      "|29.6|-1.3333333333333326|\n",
      "|-1.1| -18.38888888888889|\n",
      "+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temp_c column by applying the scalar UDF:\n",
    "gsod = gsod.withColumn(\"temp_c\", f_to_c(F.col(\"temp\")))\n",
    "gsod.select(\"temp\", \"temp_c\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterator of Series UDFs are very useful when you have an expensive cold start operation you\n",
    "need to perform. By cold start, we mean an operation we need to perform once at the\n",
    "beginning of the processing step, before working through the data. Deserializing a\n",
    "local ML model (fitted with scikit-learn or another Python modeling library) is an\n",
    "example: we would need to unpack and read the model once for the whole data\n",
    "frame, and then it could be used to process all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Iterator of Series to Iterator of Series UDF\n",
    "@F.pandas_udf(T.DoubleType())\n",
    "def f_to_c2(degrees: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    \"\"\"Transforms Farhenheit to Celcius.\"\"\"\n",
    "    # We simulate a cold start using sleep() for five seconds.\n",
    "    # The cold start will happen on each worker once, rather than for every batch.\n",
    "    sleep(5)\n",
    "    # We iterate over each batch, using yield (instead of return)\n",
    "    for batch in degrees:\n",
    "        yield (batch - 32) * 5 / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|temp|             temp_c|\n",
      "+----+-------------------+\n",
      "|37.2| 2.8888888888888906|\n",
      "|71.6| 21.999999999999996|\n",
      "|70.4| 21.333333333333336|\n",
      "|29.6|-1.3333333333333326|\n",
      "|-1.1| -18.38888888888889|\n",
      "+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsod.select(\n",
    "    \"temp\", f_to_c2(F.col(\"temp\")).alias(\"temp_c\")\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an Iterator of multiple Series to Iterator of Series to assemple the `year`, `mo` and `da` columns (representing year, month and day) into a single column:\n",
    "\n",
    "1) `year_mo_da`` is an Iterator of a tuple of Series, representing all the batches of values contained in the `year``, `mo``, and `da` columns.\n",
    "2) To access each batch, we use a for loop over the iterator, the same principle as\n",
    "for the Iterator of Series UDF.\n",
    "3) To extract each individual series from the tuple, we use multiple assignments.\n",
    "In this case, `year` will map to the first Series of the tuple, `mo` to the second, and\n",
    "`da` to the third.\n",
    "4) Since `pd.to_datetime` requests a data frame containing the year, month, and\n",
    "day columns, we create the data frame via a dictionary, giving the keys the relevant column names. `pd.to_datetime` returns a Series.\n",
    "5) Finally, we yield the answer to build the Iterator of Series, fulfilling our contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(T.DateType())\n",
    "def create_date(\n",
    "    year_mo_da: Iterator[Tuple[pd.Series, pd.Series, pd.Series]]\n",
    ") -> Iterator[pd.Series]:\n",
    "    \"\"\"Merges three sols (Y-M-D of a date) into a Date col.\"\"\"\n",
    "    for year, mo, da in year_mo_da:\n",
    "        yield pd.to_datetime(\n",
    "            pd.DataFrame(dict(year=year, month=mo, day=da))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsod.select(\n",
    "    \"year\", \"mo\", \"da\",\n",
    "    create_date(F.col(\"year\"), F.col(\"mo\"), F.col(\"da\")).alias(\"date\")\n",
    ").distinct().show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
