{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from time import sleep\n",
    "from typing import Iterator, Sequence, Tuple\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we work with 10 years' (2010 to 2020) worth of NOAA weather data located in Google BigQuery, which totals over 40 million records. The `bigquery-public-data` is a project available to all.\n",
    "\n",
    "Here, we read in a large amount of data from a warehouse and assemble a single data frame representing weather information across the globe for a period of 10 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Spark connector package version closest to our installed version of Spark (3.4.1)\n",
    "spark = SparkSession.builder.config(\n",
    "    \"spark.jars.packages\",\n",
    "    \"com.google.cloud.spark:spark-3.3-bigquery:0.32.0\"\n",
    ").config(\n",
    "    \"parentProject\", \"cool-wharf-393713\"\n",
    ").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract the table reading routine into a reusable function, returning the resulting data frame\n",
    "def read_df_from_bq(year):\n",
    "    return (\n",
    "        spark.read.format(\"bigquery\").option(\n",
    "            \"table\", f\"bigquery-public-data.noaa_gsod.gsod{year}\"\n",
    "        )\n",
    "        .option(\"credentialsFile\", \"../../../../cool-wharf-393713-73800a184f10.json\")\n",
    "        .load()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsod = (\n",
    "    reduce(\n",
    "        # use a lambda function over a list comprehension of data frames to union them all\n",
    "        lambda x, y: x.unionByName(y, allowMissingColumns=True),\n",
    "        [read_df_from_bq(year) for year in range(2010, 2021)],\n",
    "    )\n",
    "    .dropna(subset=[\"year\", \"mo\", \"da\", \"temp\"])\n",
    "    .where(F.col(\"temp\") != 9999.9)\n",
    "    .drop(\"date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas scalar UDF that transforms Fahrenheit into Celsius\n",
    "@F.pandas_udf(T.DoubleType())\n",
    "def f_to_c(degrees: pd.Series) -> pd.Series:\n",
    "    \"\"\"Transforms Fahrenheight to Celcius.\"\"\"\n",
    "    return (degrees - 32) *5 / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|temp|\n",
      "+----+\n",
      "|69.8|\n",
      "|74.5|\n",
      "|64.2|\n",
      "|76.4|\n",
      "|15.5|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsod.select(\"temp\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|temp|             temp_c|\n",
      "+----+-------------------+\n",
      "|37.2| 2.8888888888888906|\n",
      "|71.6| 21.999999999999996|\n",
      "|70.4| 21.333333333333336|\n",
      "|29.6|-1.3333333333333326|\n",
      "|-1.1| -18.38888888888889|\n",
      "+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temp_c column by applying the scalar UDF:\n",
    "gsod = gsod.withColumn(\"temp_c\", f_to_c(F.col(\"temp\")))\n",
    "gsod.select(\"temp\", \"temp_c\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterator of Series UDFs are very useful when you have an expensive cold start operation you\n",
    "need to perform. By cold start, we mean an operation we need to perform once at the\n",
    "beginning of the processing step, before working through the data. Deserializing a\n",
    "local ML model (fitted with scikit-learn or another Python modeling library) is an\n",
    "example: we would need to unpack and read the model once for the whole data\n",
    "frame, and then it could be used to process all records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Iterator of Series to Iterator of Series UDF\n",
    "@F.pandas_udf(T.DoubleType())\n",
    "def f_to_c2(degrees: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    \"\"\"Transforms Farhenheit to Celcius.\"\"\"\n",
    "    # We simulate a cold start using sleep() for five seconds.\n",
    "    # The cold start will happen on each worker once, rather than for every batch.\n",
    "    sleep(5)\n",
    "    # We iterate over each batch, using yield (instead of return)\n",
    "    for batch in degrees:\n",
    "        yield (batch - 32) * 5 / 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|temp|             temp_c|\n",
      "+----+-------------------+\n",
      "|37.2| 2.8888888888888906|\n",
      "|71.6| 21.999999999999996|\n",
      "|70.4| 21.333333333333336|\n",
      "|29.6|-1.3333333333333326|\n",
      "|-1.1| -18.38888888888889|\n",
      "+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsod.select(\n",
    "    \"temp\", f_to_c2(F.col(\"temp\")).alias(\"temp_c\")\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use an Iterator of multiple Series to Iterator of Series to assemple the `year`, `mo` and `da` columns (representing year, month and day) into a single column:\n",
    "\n",
    "1) `year_mo_da`` is an Iterator of a tuple of Series, representing all the batches of values contained in the `year``, `mo``, and `da` columns.\n",
    "2) To access each batch, we use a for loop over the iterator, the same principle as\n",
    "for the Iterator of Series UDF.\n",
    "3) To extract each individual series from the tuple, we use multiple assignments.\n",
    "In this case, `year` will map to the first Series of the tuple, `mo` to the second, and\n",
    "`da` to the third.\n",
    "4) Since `pd.to_datetime` requests a data frame containing the year, month, and\n",
    "day columns, we create the data frame via a dictionary, giving the keys the relevant column names. `pd.to_datetime` returns a Series.\n",
    "5) Finally, we yield the answer to build the Iterator of Series, fulfilling our contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(T.DateType())\n",
    "def create_date(\n",
    "    year_mo_da: Iterator[Tuple[pd.Series, pd.Series, pd.Series]]\n",
    ") -> Iterator[pd.Series]:\n",
    "    \"\"\"Merges three sols (Y-M-D of a date) into a Date col.\"\"\"\n",
    "    for year, mo, da in year_mo_da:\n",
    "        yield pd.to_datetime(\n",
    "            pd.DataFrame(dict(year=year, month=mo, day=da))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+----------+\n",
      "|year| mo| da|      date|\n",
      "+----+---+---+----------+\n",
      "|2010| 12| 20|2010-12-20|\n",
      "|2010| 08| 31|2010-08-31|\n",
      "|2010| 03| 17|2010-03-17|\n",
      "|2010| 12| 16|2010-12-16|\n",
      "|2010| 04| 03|2010-04-03|\n",
      "+----+---+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gsod.select(\n",
    "    \"year\", \"mo\", \"da\",\n",
    "    create_date(F.col(\"year\"), F.col(\"mo\"), F.col(\"da\")).alias(\"date\")\n",
    ").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.1\n",
    "\n",
    "What are the values of `WHICH_TYPE` and `WHICH_SIGNATURE` in the following code block?\n",
    "\n",
    "```\n",
    "exo9_1 = pd.Series([\"red\", \"blue\", \"blue\", \"yellow\"])\n",
    "def color_to_num(colors: WHICH_SIGNATURE) -> WHICH_SIGNATURE:\n",
    " return colors.apply(\n",
    " lambda x: {\"red\": 1, \"blue\": 2, \"yellow\": 3}.get(x)\n",
    " )\n",
    "color_to_num(exo9_1)\n",
    "# 0 1\n",
    "# 1 2\n",
    "# 2 2\n",
    "# 3 3\n",
    "color_to_num_udf = F.pandas_udf(color_to_num, WHICH_TYPE)\n",
    "\n",
    "```\n",
    "\n",
    "Answer: \n",
    "\n",
    "`WHICH_SIGNATURE`: `pd.Series`\n",
    "\n",
    "`WHICH_TYPE`: `T.IntegerType()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a grouped aggregate UDF to get the slope of temperature for a given period using sklearn\n",
    "@F.pandas_udf(T.DoubleType())\n",
    "def rate_of_change_temperature(day: pd.Series, temp: pd.Series) -> float:\n",
    "    \"\"\"Returns the slope of the daily temperature for a given period of time.\"\"\"\n",
    "    return (\n",
    "        LinearRegression()\n",
    "        .fit(X=day.astype(int).values.reshape(-1, 1), y=temp)\n",
    "        .coef_[0] # Because we only have one feature, we select the first value of coef_ as the slope\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the grouped aggregate UDF to get the rate of change of temperature \n",
    "# for each month for each station\n",
    "result = gsod.groupby(\"stn\", \"year\", \"mo\").agg(\n",
    "    rate_of_change_temperature(gsod[\"da\"], gsod[\"temp\"]).alias(\"rt_chg_temp\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---+-------------------+\n",
      "|stn   |year|mo |rt_chg_temp        |\n",
      "+------+----+---+-------------------+\n",
      "|007032|2013|01 |-0.2795031055900618|\n",
      "|008268|2010|07 |-2.1999999999999877|\n",
      "|008400|2010|02 |1.7828571428571434 |\n",
      "|008400|2010|08 |0.8514508067970873 |\n",
      "|008401|2011|03 |0.7514516129032259 |\n",
      "+------+----+---+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a group map UDF to scale temperature values.\n",
    "# Our function must return a complete DataFrame, meaning all the columns that we want to \n",
    "# display need to be returned, including the one we grouped against.\n",
    "def scale_temperature(temp_by_day: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Returns a simple normalisation of the temperature for a site.\n",
    "    \n",
    "    If the temperature is constant for the whole window, defaults to 0.5.\"\"\"\n",
    "    temp = temp_by_day.temp\n",
    "    answer = temp_by_day[[\"stn\", \"year\", \"mo\", \"da\", \"temp\"]]\n",
    "    if temp.min() == temp.max():\n",
    "        return answer.assign(temp_norm=0.5)\n",
    "    return answer.assign(\n",
    "        temp_norm=(temp - temp.min()) / (temp.max() - temp.min())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use groupby() to split the data into manageable batches, then pass our function\n",
    "# to the applyInPandas() method\n",
    "gsod_map = gsod.groupby(\"stn\", \"year\", \"mo\").applyInPandas(\n",
    "    scale_temperature,\n",
    "    schema=(\n",
    "        \"stn string, year string, mo string, \"\n",
    "        \"da string, temp double, temp_norm double\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsod_map.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.2\n",
    "\n",
    "Using the following definitions, create a `temp_to_temp(value, from_temp, to_temp)`\n",
    "that takes a numerical value in `from_temp` degrees and converts it to `to` degrees. Use\n",
    "a pandas UDF this time (we did the same exercise in chapter 8).\n",
    "- `C = (F - 32) * 5 / 9` (Celsius)\n",
    "- `K = C + 273.15` (Kelvin)\n",
    "- `R = F + 459.67` (Rankine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_to_temp(value: pd.Series, from_temp: str, to_temp: str) -> pd.Series:\n",
    "    conversion_formulas = {\n",
    "        ('F', 'C'): lambda x: (x - 32) * 5 / 9,\n",
    "        ('F', 'K'): lambda x: (x + 459.67) * 5 / 9,\n",
    "        ('F', 'R'): lambda x: x + 459.67,\n",
    "        ('C', 'F'): lambda x: x * 9 / 5 + 32,\n",
    "        ('C', 'K'): lambda x: x + 273.15,\n",
    "        ('C', 'R'): lambda x: (x + 273.15) * 9 / 5,\n",
    "        ('K', 'F'): lambda x: x * 9 / 5 - 459.67,\n",
    "        ('K', 'C'): lambda x: x - 273.15,\n",
    "        ('K', 'R'): lambda x: x * 9 / 5,\n",
    "        ('R', 'F'): lambda x: x - 459.67,\n",
    "        ('R', 'C'): lambda x: (x - 459.67) * 5 / 9,\n",
    "        ('R', 'K'): lambda x: x * 5 / 9,\n",
    "    }\n",
    "\n",
    "    if from_temp not in conversion_formulas or to_temp not in conversion_formulas:\n",
    "        return value.apply(lambda _: None)\n",
    "\n",
    "    return conversion_formulas[(from_temp, to_temp)](value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.3\n",
    "\n",
    "Modify the following code block to use Celsius degrees instead of Fahrenheit. How is\n",
    "the result of the UDF different if applied to the same data frame?\n",
    "\n",
    "```\n",
    "def scale_temperature(temp_by_day: pd.DataFrame) -> pd.DataFrame:\n",
    " \"\"\"Returns a simple normalization of the temperature for a site.\n",
    " If the temperature is constant for the whole window, defaults to 0.5.\"\"\"\n",
    " temp = temp_by_day.temp\n",
    " answer = temp_by_day[[\"stn\", \"year\", \"mo\", \"da\", \"temp\"]]\n",
    " if temp.min() == temp.max():\n",
    " return answer.assign(temp_norm=0.5)\n",
    " return answer.assign(\n",
    " temp_norm=(temp - temp.min()) / (temp.max() - temp.min())\n",
    " )\n",
    "```\n",
    "\n",
    "Answer: the output will be the same since the normalisation process does not change based on the units of temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_temperature(temp_by_day: pd.DataFrame) -> pd.DataFrame:\n",
    "   \"\"\"Returns a simple normalization of the temperature for a site.\n",
    "   If the temperature is constant for the whole window, defaults to 0.5.\"\"\"\n",
    "   def f_to_c(temp):\n",
    "     return (temp - 32.0) * 5.0 / 9.0\n",
    "   temp = f_to_c(temp_by_day.temp)\n",
    "   answer = temp_by_day[[\"stn\", \"year\", \"mo\", \"da\", \"temp\"]]\n",
    "   if temp.min() == temp.max():\n",
    "     return answer.assign(temp_norm=0.5)\n",
    "   return answer.assign(\n",
    "      temp_norm=(temp - temp.min()) / (temp.max() - temp.min())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.4\n",
    "\n",
    "Complete the schema of the following code block, using scale_temperature_C from\n",
    "the previous exercise. What happens if we apply our group map UDF like so instead?\n",
    "\n",
    "```\n",
    "gsod_exo = gsod.groupby(\"year\", \"mo\").applyInPandas(scale_temperature, schema=???)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=(\n",
    "        \"year string, mo string, \"\n",
    "        \"temp double, temp_norm double\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9.5\n",
    "\n",
    "Modify the following code block to return both the intercept of the linear regression\n",
    "as well as the slope in an ArrayType. (Hint: The intercept is in the intercept_ attribute of the fitted model.)\n",
    "\n",
    "```\n",
    "@F.pandas_udf(T.DoubleType())\n",
    "def rate_of_change_temperature(day: pd.Series, temp: pd.Series) -> float:\n",
    " \"\"\"Returns the slope of the daily temperature for a given period of \n",
    "time.\"\"\"\n",
    " return (\n",
    " LinearRegression()\n",
    " .fit(X=day.astype(\"int\").values.reshape(-1, 1), y=temp)\n",
    " .coef_[0]\n",
    " )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(T.ArrayType(T.DoubleType()))\n",
    "def rate_of_change_temperature(day: pd.Series, temp: pd.Series) -> Sequence[float]:\n",
    "    \"\"\"Returns the intercept and slope of the daily temperature for a given period of time.\"\"\"\n",
    "    model = LinearRegression().fit(X=day.astype(\"int\").values.reshape(-1, 1), y=temp)\n",
    "    return model.intercept_, model.coef_[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
